{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X7DD2yUxnPCW"
   },
   "source": [
    "$$\\text{Parallélisation d'une décomposition de Cholesky}$$\n",
    "\n",
    "$$\\text{Florian Schirrer _ Caroline Boudier }$$\n",
    "\n",
    "$$\\textit{Éleménts Logiciels pour le traitement des Données Massives 2021}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NnHc6OuMt661"
   },
   "source": [
    "# Pré-requis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RF_J1zBat_8t",
    "outputId": "b035f0c2-15bd-4bc1-df29-c101d7e13993"
   },
   "outputs": [],
   "source": [
    "# packages\n",
    "from sklearn.datasets import make_spd_matrix\n",
    "from numpy.testing import assert_almost_equal\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cython\n",
    "%load_ext cython\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Ifvzt7unytw"
   },
   "source": [
    "# I) Fonctions Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mbq1miuLokXI"
   },
   "source": [
    "On va coder en Python deux versions classiques de la décomposition de Cholesky : \n",
    "- Cholesky-Banachiewicz\n",
    "- Cholesky-Crout. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jBd70Akbvj1W"
   },
   "source": [
    "## A) Cholesky-Banachiewicz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j2epSRl6sUY0"
   },
   "outputs": [],
   "source": [
    "def python_Bana(A):\n",
    "  # taille de la matrice\n",
    "  n=len(A)\n",
    "  # on crée une matrice vide\n",
    "  L=np.zeros((n,n))\n",
    "  # on parcourt ses lignes\n",
    "  for i in range(n):\n",
    "    # puis ses colonnes\n",
    "    for j in range(i+1):\n",
    "      s=0\n",
    "      # calcul de la somme\n",
    "      for k in range(j):\n",
    "        s+=L[i][k]*L[j][k]\n",
    "      if (i==j):\n",
    "        L[i][j]=(A[i][i]-s)**0.5\n",
    "      else:\n",
    "        L[i][j]=(1.0/L[j][j])*(A[i][j]-s)\n",
    "  return(L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ylMqTdc0wc-7",
    "outputId": "49ac8b6b-2ee7-466f-fe24-6eb8f7467f35"
   },
   "outputs": [],
   "source": [
    "N=make_spd_matrix(n_dim=100)\n",
    "# on vérifie le résultat - fonction baseline = tensorflow\n",
    "assert_almost_equal(tf.linalg.cholesky(N),python_Bana(N),decimal=5)\n",
    "\n",
    "# on compare les temps pour se faire une première idée\n",
    "print('temps Python Bana')\n",
    "%timeit -o python_Bana(N)\n",
    "print('temps baseline tensorflow')\n",
    "%timeit -o tf.linalg.cholesky(N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pAr99pEuwEt9"
   },
   "source": [
    "## B) Cholesky-Crout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J8-cBLKpswy6"
   },
   "outputs": [],
   "source": [
    "def python_Crout(A):\n",
    "    n=len(A)\n",
    "    # on crée une matrice vide\n",
    "    L = np.zeros((n,n))\n",
    "    # on parcourt ses colonnes\n",
    "    for j in range(n):\n",
    "        s=0.0\n",
    "        for k in range(j):\n",
    "            s+=L[j][k]*L[j][k]\n",
    "        L[j][j]=np.sqrt((A[j][j]-s))\n",
    "        # puis ses lignes\n",
    "        for i in range(j+1,n):\n",
    "            s = 0\n",
    "            for k in range(j):\n",
    "                s+=L[i][k]*L[j][k]\n",
    "            \n",
    "            L[i][j]=(1.0/L[j][j])*(A[i][j]-s)\n",
    "    return(L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HJLLzh54ws3g",
    "outputId": "d391e3dd-dfa7-40c9-bd2d-10674c70739d"
   },
   "outputs": [],
   "source": [
    "N=make_spd_matrix(n_dim=100)\n",
    "# on vérifie le résultat\n",
    "assert_almost_equal(tf.linalg.cholesky(N),python_Crout(N),decimal=5)\n",
    "\n",
    "# on compare les temps pour se faire une première idée\n",
    "print('temps Python Crout')\n",
    "%timeit -o python_Crout(N)\n",
    "print('temps baseline tensorflow')\n",
    "%timeit -o tf.linalg.cholesky(N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Z7KYNBGn-Fd"
   },
   "source": [
    "# II) Parallélisation de l'algorithme des colonnes (Cholesky-Crout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9KerPoUB2VwZ"
   },
   "source": [
    "Comme décrit dans le rapport nous décidons de paralléliser la version Cholesky-Crout de l'algorithme plutôt que la version Cholesky Banachiewicz."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OhCWAm6X8KBE"
   },
   "source": [
    "### A) Premières optimisations (indépendantes d'une parallélisation). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xP5crqc68V0O"
   },
   "source": [
    "On commence par compiler le code avec Cython en apportant plusieurs améliorations : \n",
    "- on définit les types de variables (afin d'éviter de créer des objets Python)\n",
    "- on crée des memory views qui pointeront vers nos arrays numpy.\n",
    "- on enlève le \"bounds checking\" (vérifie que les indices sont cohérents) et le wraparound, on intègre aussi une division de type C. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 685
    },
    "id": "r0DkhQG44cpV",
    "outputId": "cd53d222-9b32-4ae1-bc65-ef04478d79ac"
   },
   "outputs": [],
   "source": [
    "%%cython -a\n",
    "import numpy as np\n",
    "cimport cython \n",
    "\n",
    "@cython.boundscheck(False) # retire le boundschecking\n",
    "@cython.wraparound(False) # retire le wraparound\n",
    "@cython.cdivision(True) # division de type C\n",
    "\n",
    "def cython_cholesky_crout(double[:,:] A):\n",
    "    # on définit les types de valeurs pour i,j,k,n, s\n",
    "    cdef Py_ssize_t n=len(A)\n",
    "    cdef Py_ssize_t i,j,k\n",
    "    cdef float s\n",
    "    \n",
    "    # on initialise à 0 une matrice L\n",
    "    L = np.zeros((n,n))\n",
    "    \n",
    "    # on crée des memory views\n",
    "    cdef double[:,:] L_view=L\n",
    "    cdef double[:,:] A_view=A\n",
    "\n",
    "    # on boucle sur les colonnes\n",
    "    for j in range(n):\n",
    "        s=0.0\n",
    "        for k in range(j):\n",
    "            s+=L_view[j][k]*L_view[j][k]\n",
    "        \n",
    "        L_view[j][j]=(A_view[j][j]-s)**0.5\n",
    "        # puis sur les lignes\n",
    "        for i in range(j+1,n):\n",
    "            s = 0\n",
    "            for k in range(j):\n",
    "                s+=L_view[i][k]*L_view[j][k]\n",
    "            \n",
    "            L_view[i][j]=(1.0/L_view[j][j])*(A_view[i][j]-s)\n",
    "\n",
    "    return(L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CAALmVWd6dQI",
    "outputId": "69afb7dc-cc23-4808-d694-56dbf44393db"
   },
   "outputs": [],
   "source": [
    "N=make_spd_matrix(n_dim=100)\n",
    "# on vérifie le résultat\n",
    "assert_almost_equal(cython_cholesky_crout(N),tf.linalg.cholesky(N),decimal=5)\n",
    "\n",
    "# on compare les temps\n",
    "print('fonction Python de base: ')\n",
    "%timeit -o python_Crout(N)\n",
    "print('fonction Python compilée en Cython avec optimisations')\n",
    "%timeit -o cython_cholesky_crout(N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "At0C7hVQ9qb_"
   },
   "source": [
    "### B) Parallélisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NjCu0XkMI-_k"
   },
   "source": [
    "On va maintenant paralléliser la fonction. À noter que notre fonction prend en entrée : la matrice, le nombre de threads (fixé par défaut à une valeur de 8) et un cut-off (fixé par défaut à 0). Le cutoff est ici défini comme la proportion non parallélisée de l'algorithme, autrement dit si on fixe un cutoff à 20%, la parallélisation se fera sur les 80% des premières colonnes et le reste en séquentiel. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RvTrt2xhJsmK"
   },
   "outputs": [],
   "source": [
    "%%cython\n",
    "\n",
    "# distutils: extra_compile_args = -fopenmp\n",
    "# distutils: extra_link_args = -fopenmp\n",
    "\n",
    "import numpy as np\n",
    "from cython.parallel cimport prange\n",
    "cimport cython \n",
    "\n",
    "@cython.boundscheck(False) \n",
    "@cython.wraparound(False) \n",
    "@cython.cdivision(True) \n",
    "\n",
    "def cython_cholesky_crout_par(double[:,:] A,int n_threads=8,float cutoff=0):\n",
    "    cdef Py_ssize_t n=len(A)\n",
    "    cdef Py_ssize_t i,j,k\n",
    "    cdef float s\n",
    "    L = np.zeros((n,n))\n",
    "    cdef double[:,:] L_view=L\n",
    "    cdef double[:,:] A_view=A\n",
    "    for j in range(n):\n",
    "        s=0.0\n",
    "        for k in range(j):\n",
    "            s+=L_view[j][k]*L_view[j][k]\n",
    "        \n",
    "        L_view[j][j]=(A_view[j][j]-s)**0.5\n",
    "        \n",
    "        # la parallélisation intervient ici\n",
    "        if j<n-int(n*cutoff):\n",
    "            for i in prange(j+1,n,nogil=True,schedule='static',num_threads=n_threads):\n",
    "                s = 0\n",
    "                for k in range(j):\n",
    "                    s=s+L_view[i][k]*L_view[j][k]\n",
    "            \n",
    "                L_view[i][j]=(1.0/L_view[j][j])*(A_view[i][j]-s)\n",
    "        else:\n",
    "            for i in range(j+1,n):\n",
    "                s = 0\n",
    "                for k in range(j):\n",
    "                    s=s+L_view[i][k]*L_view[j][k]\n",
    "            \n",
    "                L_view[i][j]=(1.0/L_view[j][j])*(A_view[i][j]-s)\n",
    "            \n",
    "    return(L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ut7erCYRKrLQ",
    "outputId": "e36e2317-41c8-4bc6-a6dc-4b47b1ebf06d"
   },
   "outputs": [],
   "source": [
    "N=make_spd_matrix(1000)\n",
    "# on vérifie le résultat\n",
    "assert_almost_equal(cython_cholesky_crout_par(N),tf.linalg.cholesky(N),decimal=3)\n",
    "\n",
    "# on affiche quelques temps pour se faire une première idée\n",
    "print('Cholesky Crout non parallélisé')\n",
    "%timeit cython_cholesky_crout(N)\n",
    "print('Cholesky Crout parallélisé - 2 threads - pas de cutoff')\n",
    "%timeit cython_cholesky_crout_par(N,n_threads=2)\n",
    "print('Cholesky Crout parallélisé - 8 threads - pas de cutoff')\n",
    "%timeit cython_cholesky_crout_par(N,n_threads=8)\n",
    "print('Cholesky Crout parallélisé - 8 threads -cutoff de 50%')\n",
    "%timeit cython_cholesky_crout_par(N,n_threads=8,cutoff=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z74E_9lSoC96"
   },
   "source": [
    "# III) Parallélisation d'un algorithme optimisé (vecteurs plutôt que matrices). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OCxk-HpR6VuC"
   },
   "source": [
    "## A) Version non parallélisée"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MluHMl2AEYuQ"
   },
   "source": [
    "On implémente maintenant la version contigüe en représentant nos matrices par des vecteurs. Afin d'accélérer nos calculs, nous ne passons pas par un mermoyview, mais nous introduisons deux pointeurs: un sur la matrice A et un sur la matrice L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "evZeXP-Tw2PJ",
    "outputId": "dc9cd4d9-6bae-400f-8190-f1f0e3c44738"
   },
   "outputs": [],
   "source": [
    "%%cython -a\n",
    "import numpy as np\n",
    "cimport cython \n",
    "cimport numpy as np\n",
    "from cpython cimport array\n",
    "\n",
    "@cython.boundscheck(False) # retire le boundschecking\n",
    "@cython.wraparound(False) # retire le wraparound\n",
    "@cython.cdivision(True) # division de type C\n",
    "\n",
    "def cython_cholesky_crout_vect(np.ndarray A):\n",
    "    # on définit les types de valeurs pour i,j,k,n, s\n",
    "    cdef Py_ssize_t n=len(A)\n",
    "    cdef Py_ssize_t i,j,k\n",
    "    cdef double s\n",
    "    \n",
    "    #On représente la matrice 2D sous la forme d'un vecteur 1D\n",
    "    cdef np.ndarray A_reshape = A.reshape(n*n)\n",
    "    \n",
    "    #Pointeur sur la forme contigüe de L\n",
    "    cdef np.ndarray[double, ndim=1, mode = 'c'] L = np.zeros(n*n)\n",
    "    cdef double* L_view = <double*> L.data\n",
    "\n",
    "    #Pointeur sur la forme contigüe de A\n",
    "    cdef double* A_view = <double*> A_reshape.data\n",
    "    for j in range(n):\n",
    "        s=0.0\n",
    "        for k in range(j):\n",
    "            s+=L_view[j*n+k]*L_view[j*n+k]\n",
    "        \n",
    "        L_view[j*n+j]=(A_view[j*n+j]-s)**0.5\n",
    "        \n",
    "        for i in range(j+1,n):\n",
    "            s = 0\n",
    "            for k in range(j):\n",
    "                s+=L_view[i*n+k]*L_view[j*n+k]\n",
    "            \n",
    "            L_view[i*n+j]=(1.0/L_view[j*n+j])*(A_view[i*n+j]-s)\n",
    "\n",
    "    return(L.reshape((n,n)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p7oskpaJpht7",
    "outputId": "e07b69aa-a647-42c0-eb29-df24f417be82"
   },
   "outputs": [],
   "source": [
    "N=make_spd_matrix(n_dim=1000)\n",
    "# on vérifie le résultat\n",
    "assert_almost_equal(cython_cholesky_crout_vect(N),tf.linalg.cholesky(N),decimal=3)\n",
    "print('Cholesky Crout simple :')\n",
    "%timeit -o cython_cholesky_crout(N)\n",
    "print('Cholesky vectorisé simple')\n",
    "%timeit -o cython_cholesky_crout_vect(N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6EXV6iZUY9jc"
   },
   "source": [
    "## B) Version parallélisée"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s_NA--ZF6Z5u"
   },
   "source": [
    "On crée une seconde version paralllélisée. De même que pour l'algorithme non vectorisé on prend en compte le nombre de threads et le cutoff. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "PluwYidExdo0",
    "outputId": "79252c27-a89c-4fbb-850e-2ec61beaa3b0"
   },
   "outputs": [],
   "source": [
    "%%cython -a\n",
    "# distutils: extra_compile_args = -fopenmp\n",
    "# distutils: extra_link_args = -fopenmp\n",
    "import numpy as np\n",
    "from cython.parallel cimport prange\n",
    "cimport cython \n",
    "cimport numpy as np\n",
    "from cpython cimport array\n",
    "\n",
    "@cython.boundscheck(False) # retire le boundschecking\n",
    "@cython.wraparound(False) # retire le wraparound\n",
    "@cython.cdivision(True) # division de type C\n",
    "\n",
    "def cython_cholesky_crout_vect_par(np.ndarray A,int n_threads=8,float cutoff=0):\n",
    "    # on définit les types de valeurs pour i,j,k,n, s\n",
    "    cdef Py_ssize_t n=len(A)\n",
    "    cdef Py_ssize_t i,j,k\n",
    "    cdef double s\n",
    "    cdef np.ndarray A_reshape = A.reshape(n*n)\n",
    "    cdef np.ndarray[double, ndim=1, mode = 'c'] L = np.zeros(n*n)\n",
    "    \n",
    "    # création de pointeurs\n",
    "    cdef double* L_view = <double*> L.data\n",
    "    cdef double* A_view = <double*> A_reshape.data\n",
    "    for j in range(n):\n",
    "        s=0.0\n",
    "        for k in range(j):\n",
    "            s+=L_view[j*n+k]*L_view[j*n+k]\n",
    "        \n",
    "        L_view[j*n+j]=(A_view[j*n+j]-s)**0.5\n",
    "        \n",
    "        #parallélisation avec cutoff\n",
    "        if j<n-int(n*cutoff):\n",
    "          for i in prange(j+1,n,nogil=True,schedule='static',num_threads=n_threads):\n",
    "            s = 0\n",
    "            for k in range(j):\n",
    "              s=s+L_view[i*n+k]*L_view[j*n+k]\n",
    "            L_view[i*n+j]=(1.0/L_view[j*n+j])*(A_view[i*n+j]-s)\n",
    "        else:\n",
    "          for i in range(j+1,n):\n",
    "            s = 0\n",
    "            for k in range(j):\n",
    "              s=s+L_view[i*n+k]*L_view[j*n+k]\n",
    "            L_view[i*n+j]=(1.0/L_view[j*n+j])*(A_view[i*n+j]-s)\n",
    "\n",
    "    return(L.reshape((n,n)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5tVjuRpLYyzB",
    "outputId": "80f5c6e0-dfd7-4567-c174-73dcbb927e3b"
   },
   "outputs": [],
   "source": [
    "N=make_spd_matrix(1000)\n",
    "# on vérifie le résultat\n",
    "assert_almost_equal(cython_cholesky_crout_vect_par(N),tf.linalg.cholesky(N),decimal=3)\n",
    "\n",
    "# on affiche quelques temps pour se faire une première idée\n",
    "print('Cholesky Crout vectorisé non parallélisé')\n",
    "%timeit cython_cholesky_crout_vect(N)\n",
    "print('Cholesky Crout vectorisé parallélisé - 2 threads - pas de cutoff')\n",
    "%timeit cython_cholesky_crout_vect_par(N,n_threads=2)\n",
    "print('Cholesky Crout vectorisé parallélisé - 8 threads - pas de cutoff')\n",
    "%timeit cython_cholesky_crout_vect_par(N,n_threads=8)\n",
    "print('Cholesky Crout vectorisé parallélisé - 8 threads -cutoff de 50%')\n",
    "%timeit cython_cholesky_crout_vect_par(N,n_threads=8,cutoff=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZfWiGolPoalR"
   },
   "source": [
    "# IV) Comparaison des temps et visualisation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z8P8hEswzyya"
   },
   "source": [
    "L'idée va être : \n",
    "\n",
    "- de comparer la version parallélisée et non parallélisée en calculant les temps d'exécution pour différentes tailles de matrices, les speed-ups, l'efficacité et la variation en fonction de certains paramètres (nombre de threads, cut-offs). \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P_8Ft9bocVUV"
   },
   "source": [
    "## A) Temps d'exécution et speed-up en fonction de la taille de la matrice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uKTiOIF5cqeO"
   },
   "source": [
    "Les temps d'exécution sont pour l'instant calculés pour une utilisation maximale des capacités (8 threads) et sans cut-off. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HXL8MKG1cikF",
    "outputId": "98fdc5ad-a142-487a-e025-1fe04bf57901"
   },
   "outputs": [],
   "source": [
    "vect=[100,500,750,1000,2500,5000]\n",
    "threads_def=8\n",
    "cutoff_def=0.0\n",
    "\n",
    "# dictionnaire d'arrivée\n",
    "result_dict={'matrix_size':vect,\n",
    "             'CC_simple':[],\n",
    "             'CC_par':[],\n",
    "             'speed_up_CC':[],\n",
    "             'vect_simple':[],\n",
    "             'vect_par':[],\n",
    "             'vect_speedup':[],\n",
    "             'baseline_tensorflow':[]\n",
    "             }\n",
    "\n",
    "for n in vect:\n",
    "  # on crée une matrice de taille N\n",
    "  A=make_spd_matrix(n)\n",
    "  \n",
    "  # temps pour l'algo colonnes\n",
    "    #col \n",
    "  t_col=%timeit -o -r 3 cython_cholesky_crout(A)\n",
    "  result_dict['CC_simple'].append(t_col.best)\n",
    "   #col par\n",
    "  t_col_par= %timeit -o -r 3 cython_cholesky_crout_par(A,n_threads=threads_def,cutoff=cutoff_def)\n",
    "  result_dict['CC_par'].append(t_col_par.best)\n",
    "    #col speed_up\n",
    "  result_dict['speed_up_CC'].append(t_col.best/t_col_par.best)\n",
    "\n",
    "  # temps pour vecteur \n",
    "    # vecteur normal \n",
    "  t_vect= %timeit -o -r 3 cython_cholesky_crout_vect(A)\n",
    "  result_dict['vect_simple'].append(t_vect.best)\n",
    "    # vecteur parallélisé \n",
    "  t_vect_par= %timeit -o -r 3 cython_cholesky_crout_vect_par(A,n_threads=threads_def,cutoff=cutoff_def)\n",
    "  result_dict['vect_par'].append(t_vect_par.best)\n",
    "    # speed-up vecteur \n",
    "  result_dict['vect_speedup'].append(t_vect.best/t_vect_par.best)\n",
    "\n",
    "  # temps pour tensorflow\n",
    "  tf_time= %timeit -o -r 3 tf.linalg.cholesky(A)\n",
    "  result_dict['baseline_tensorflow'].append(tf_time.best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 257
    },
    "id": "8ooog23RdkSt",
    "outputId": "dbbd8bae-10dc-42f6-8de0-4d622b1e4936"
   },
   "outputs": [],
   "source": [
    "# on affiche les résultats\n",
    "results_df=pd.DataFrame.from_dict(result_dict)\n",
    "results_df=results_df.set_index('matrix_size')\n",
    "results_df.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 607
    },
    "id": "WP_NCVgXd9E4",
    "outputId": "61558aa6-c368-4ec2-8016-240ade3ec3ca"
   },
   "outputs": [],
   "source": [
    "#graphique pour les temps d'exécution et pour les speed-ups\n",
    "results_df.plot(y=['CC_simple','CC_par','vect_simple','vect_par','baseline_tensorflow'],title='Temps d\\'exécution pour nos différents algorithmes en fonction de la taille de la matrice')\n",
    "results_df.plot(y=['speed_up_CC','vect_speedup'],title='Speed-Up pour nos deux algorithmes',kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qpHkWsbhfkOi"
   },
   "source": [
    "## B) Impact du nombre de threads et du cut-off"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p2Y7sy9qfzDt"
   },
   "source": [
    "Impact du nombre de threads : on va calculer l'évolution du speed-up et de l'efficacité pour une matrice de taille définie. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZrbPZffmgAMG",
    "outputId": "e0d2441b-1549-4a86-a92c-e8f0e780cfa3"
   },
   "outputs": [],
   "source": [
    "# Plot pour le nombre de threads\n",
    "mat=make_spd_matrix(3000)\n",
    "\n",
    "n_threads=[1,2,4,6,8]\n",
    "\n",
    "# dictionnaire d'arrivée\n",
    "result_threads_dict={}\n",
    "\n",
    "for i in n_threads:\n",
    "  result_threads_dict[i]=[]\n",
    "  #time_col\n",
    "  t_col=%timeit -o cython_cholesky_crout_par(mat,n_threads=i)\n",
    "    #time\n",
    "  result_threads_dict[i].append(t_col.best)\n",
    "    #speed-up\n",
    "  result_threads_dict[i].append(result_threads_dict[1][0]/t_col.best)\n",
    "    #efficieny\n",
    "  result_threads_dict[i].append(result_threads_dict[i][1]/i)\n",
    "\n",
    "  #time_vect\n",
    "  t_vect=%timeit -o cython_cholesky_crout_vect_par(mat,n_threads=i)\n",
    "    #time\n",
    "  result_threads_dict[i].append(t_vect.best)\n",
    "    #speed-up\n",
    "  result_threads_dict[i].append(result_threads_dict[1][3]/t_vect.best)\n",
    "    # efficiency\n",
    "  result_threads_dict[i].append(result_threads_dict[i][4]/i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 227
    },
    "id": "_Wd4odPQgPOf",
    "outputId": "371c01dc-a847-40bc-dac0-208115f4caf9"
   },
   "outputs": [],
   "source": [
    "# on affiche nos résultats\n",
    "results_th_df=pd.DataFrame.from_dict(result_threads_dict,orient='index',columns=['Temps Cholesky-Crout','Speed-up CC','Efficacité CC','Temps Vecteur','Speed-Up Vecteur','Efficacité Vecteur'])\n",
    "results_th_df.index.name='Nombre de threads'\n",
    "results_th_df=results_th_df.round(2)\n",
    "results_th_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 591
    },
    "id": "vItpzzMGgbDL",
    "outputId": "eca7d217-cadf-49f1-f474-7d8c85282408"
   },
   "outputs": [],
   "source": [
    "# on trace un graphique pour représenter efficacité et speed-up en fonction du nombre de threads\n",
    "results_th_df.plot(y=['Speed-up CC','Speed-Up Vecteur'],title='Speed-Up pour nos deux algorithmes en fonction du nombre de threads',xlabel='Nombre de threads',kind='bar',rot=0)\n",
    "#plt.plot(results_th_df['Crout_speed_up'],label=n_threads)\n",
    "results_th_df.plot(y=['Efficacité CC','Efficacité Vecteur'],title='Efficacité pour nos deux algorithmes en fonction du nombre de threads',xlabel='Nombre de threads',rot=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a6AC1YmNqsgu"
   },
   "source": [
    "Impact du cut-off : on va calculer l'évolution du temps d'exécution en fonction du cut-off pour deux matrices de taille différente. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tAEFzbLeq1i8",
    "outputId": "d8fe8b7f-520a-4484-df8e-6a955bd11b16"
   },
   "outputs": [],
   "source": [
    "small_mat=make_spd_matrix(50)\n",
    "big_mat=make_spd_matrix(300)\n",
    "cutoff_range = [i/10 for i in range(11)]\n",
    "\n",
    "co_dict={'cut_off':cutoff_range,\n",
    "         'small_mat_CC':[],\n",
    "         'big_mat_CC':[],\n",
    "         'small_mat_vect':[],\n",
    "         'big_mat_vect':[]\n",
    "         }\n",
    "\n",
    "for co in cutoff_range:\n",
    "  print(co)\n",
    "  # columns\n",
    "  t_small=%timeit -o cython_cholesky_crout_par(small_mat,cutoff=co,n_threads=2)\n",
    "  co_dict['small_mat_CC'].append(t_small.best)\n",
    "  t_big=%timeit -o cython_cholesky_crout_par(big_mat,cutoff=co,n_threads=2)\n",
    "  co_dict['big_mat_CC'].append(t_big.best)\n",
    "  # vect\n",
    "  t_small_vect=%timeit -o cython_cholesky_crout_vect_par(small_mat,cutoff=co,n_threads=2)\n",
    "  co_dict['small_mat_vect'].append(t_small_vect.best)\n",
    "  t_big_vect=%timeit -o cython_cholesky_crout_vect_par(big_mat,cutoff=co,n_threads=2)\n",
    "  co_dict['big_mat_vect'].append(t_big_vect.best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 377
    },
    "id": "8f40RkvktA_w",
    "outputId": "a6e51078-1a02-44d5-bb33-9706dc28bce7"
   },
   "outputs": [],
   "source": [
    "results_th_df=pd.DataFrame.from_dict(co_dict)\n",
    "results_th_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 596
    },
    "id": "q_T8PdTMt1I4",
    "outputId": "740b3a00-7578-4e8b-d54f-15994e1184f2"
   },
   "outputs": [],
   "source": [
    "results_th_df.plot(x='cut_off',y=['small_mat_CC','small_mat_vect'],title='Évolution du temps d\\'exécution pour une matrice de taille 50*50')\n",
    "results_th_df.plot(x='cut_off',y=['big_mat_CC','big_mat_vect'],title='Évolution du temps d\\'exécution pour une matrice de taille 300*300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a8fTnElvnp-x"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "jBd70Akbvj1W",
    "bGooTnrbcNTo"
   ],
   "name": "Florian_Caroline_Données_massives.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
